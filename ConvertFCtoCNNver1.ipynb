{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/rajagopalmotivate/FullyConvNetwork/blob/master/ConvertFCtoCNNver1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "N68XOKW4iru2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rRtkRxHziteg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2977
        },
        "outputId": "089fdb90-b1a6-42ee-d0f8-c28c9aacb0d3"
      },
      "cell_type": "code",
      "source": [
        "from keras import  layers\n",
        "from keras import models\n",
        "from keras.datasets import mnist\n",
        "from keras import  utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = models.Sequential()\n",
        "layer1c = layers.Conv2D(32, (5,5), activation='relu', input_shape=(28,28,1) )\n",
        "layer1m = layers.MaxPooling2D(pool_size=(2,2), strides=2)\n",
        "#layer2c = layers.Conv2D(64, (3,3), activation='relu')\n",
        "#layer2m = layers.MaxPooling2D(2,2)\n",
        "\n",
        "model.add(layer1c)\n",
        "model.add(layer1m)\n",
        "#model.add(layer2c)\n",
        "#model.add(layer2m)\n",
        "\n",
        "layerFlatten = layers.Flatten()\n",
        "layerd1 = layers.Dense(64, activation='relu')\n",
        "layerd2 = layers.Dense(10, activation='softmax' )\n",
        "\n",
        "layerd1FULLYCON =  layers.Conv2D(64, (12,12), activation='relu' )\n",
        "layerd2FULLYCON =  layers.Conv2D(10, (1,1), activation='softmax' )\n",
        "\n",
        "\n",
        "#layerd1 = layers.Conv2D(64, (3,3), activation='relu')\n",
        "#layerd2 = layers.Dense(10, activation='softmax' )\n",
        "\n",
        "Archi='FULLYCONNECTED'\n",
        "\n",
        "if(Archi=='FULLYCONNECTED'):\n",
        "    model.add( layerd1FULLYCON )\n",
        "    model.add( layerd2FULLYCON )\n",
        "else:\n",
        "    model.add( layerFlatten )\n",
        "    model.add( layerd1 )\n",
        "    model.add( layerd2 )\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\n",
        "print(\"No of Training samples = \" + str(len(trainX)) )\n",
        "print(\"No of Test samples = \" + str(len(testX)) )\n",
        "\n",
        "trainSetSize = len(trainX)\n",
        "testSetSize = len(testX)\n",
        "\n",
        "trainX = trainX[0:trainSetSize]\n",
        "trainY = trainY[0:trainSetSize]\n",
        "\n",
        "testX = testX[0:testSetSize]\n",
        "testY = testY[0:testSetSize]\n",
        "\n",
        "\n",
        "trainX = trainX.astype('float') * 1 /255\n",
        "testX = testX.astype('float') * 1 /255\n",
        "\n",
        "print( \"Shape of trainX = \" + str(trainX.shape) )\n",
        "\n",
        "\n",
        "trainXready = trainX.reshape((trainSetSize, 28, 28, 1))\n",
        "testXready = testX.reshape((testSetSize, 28, 28, 1))\n",
        "\n",
        "print( \"Shape of trainXready = \" + str(trainXready.shape) )\n",
        "\n",
        "\n",
        "trainYready = utils.to_categorical(trainY)\n",
        "testYready = utils.to_categorical(testY)\n",
        "\n",
        "trainYreadyTENSOR = trainYready.reshape(60000, 1, 1, 10)\n",
        "testYreadyTENSOR = testYready.reshape(10000, 1, 1, 10)\n",
        "\n",
        "\n",
        "print(' a sample from trainY:' + str(trainY[0]))\n",
        "print(' a sample from trainYready:' + str(trainYready[0]))\n",
        "print(' shape of  trainX[o]:' + str((trainX[0]).shape))\n",
        "print(' shape of  trainYreadyTENSOR[o]:' + str((trainYreadyTENSOR[0]).shape))\n",
        "\n",
        "print(' a sample from trainYreadyTENSOR:' + str(trainYreadyTENSOR[0]))\n",
        "\n",
        "print(' a sample from trainX:' + str(trainX[0]))\n",
        "\n",
        "\n",
        "\n",
        "print( \"Shape of trainY = \" + str(trainY.shape) )\n",
        "\n",
        "print( \"Shape of trainYready = \" + str(trainYready.shape) )\n",
        "print( \"Shape of trainYreadyTENSOR = \" + str(trainYreadyTENSOR.shape) )\n",
        "\n",
        "\n",
        "model.compile( optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'] )\n",
        "\n",
        "# batchsize 32, epoch 20, Test Accracy \n",
        "# batchsize 64, epoch 5 , Test Accuracy 99.16%\n",
        "\n",
        "model.fit(trainXready, trainYreadyTENSOR, batch_size=32, epochs=2)\n",
        "\n",
        "testLoss, testAccuracy = model.evaluate(testXready, testYreadyTENSOR)\n",
        "\n",
        "print(\"Test Accuracy : \" + str(testAccuracy) )\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 1, 1, 64)          294976    \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 1, 1, 10)          650       \n",
            "=================================================================\n",
            "Total params: 296,458\n",
            "Trainable params: 296,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "No of Training samples = 60000\n",
            "No of Test samples = 10000\n",
            "Shape of trainX = (60000, 28, 28)\n",
            "Shape of trainXready = (60000, 28, 28, 1)\n",
            " a sample from trainY:5\n",
            " a sample from trainYready:[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " shape of  trainX[o]:(28, 28)\n",
            " shape of  trainYreadyTENSOR[o]:(1, 1, 10)\n",
            " a sample from trainYreadyTENSOR:[[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]]\n",
            " a sample from trainX:[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
            "  0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
            "  0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "  0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
            "  0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
            "  0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
            "  0.99215686 0.35294118 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.54509804\n",
            "  0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.04313725\n",
            "  0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
            "  0.09803922 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
            "  0.58823529 0.10588235 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
            "  0.99215686 0.73333333 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.97647059\n",
            "  0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
            "  0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
            "  0.98039216 0.71372549 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.09411765 0.44705882\n",
            "  0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
            "  0.30588235 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.21568627 0.6745098\n",
            "  0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
            "  0.52156863 0.04313725 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.53333333 0.99215686\n",
            "  0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "Shape of trainY = (60000,)\n",
            "Shape of trainYready = (60000, 10)\n",
            "Shape of trainYreadyTENSOR = (60000, 1, 1, 10)\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 0.1410 - acc: 0.9575\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 15s 248us/step - loss: 0.0505 - acc: 0.9854\n",
            "10000/10000 [==============================] - 1s 86us/step\n",
            "Test Accuracy : 0.9838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UJ1-RIQ4iuQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1050
        },
        "outputId": "07bd3868-4a7c-43fb-8170-fc0213191ed4"
      },
      "cell_type": "code",
      "source": [
        "randomimage = 20\n",
        "\n",
        "sampleimage = testXready[20]\n",
        "\n",
        "plt.imshow(sampleimage)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-49715a4edcb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msampleimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestXready\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3099\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3100\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3101\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3102\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3103\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5129\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5131\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5132\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    620\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    621\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAFOCAYAAAA2HY52AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkB9hmQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1236b974e0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ayfHXpb5jjK4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}